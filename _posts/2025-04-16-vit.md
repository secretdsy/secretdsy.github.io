---
title: "[ë…¼ë¬¸ ë¦¬ë·°] An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale"
date: 2025-04-16 14:00:00 +0900
categories: [Paper]
tags: [Transformer, Vision, ViT]
math: true
toc: true
---

## ğŸ“ ë…¼ë¬¸ ì •ë³´

- **ì œëª©**: An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale  
- **ì €ì**: Dosovitskiy et al.  
- **í•™íšŒ/ì—°ë„**: ICLR 2021  
- **ë§í¬**: [https://arxiv.org/pdf/2010.11929](https://arxiv.org/pdf/2010.11929)

---

## 1. Introduction

- prepend class token
- 2d PE
- Vision Transformer has much less image-specific inductive bias than CNNs
- patch sizeê°€ ì‘ì„ìˆ˜ë¡ sequence lengthëŠ” ì»¤ì§ -> ì—°ì‚°ëŸ‰ : ViT-16 > ViT-32
- ë°ì´í„°ì…‹ì´ ì–¼ë§ˆë‚˜ í° ì˜í–¥ì„ ë¯¸ì¹ ê¹Œ? 
    - í° ë°ì´í„°ì…‹ì—ì„œëŠ” vitê°€ ë” ì¢‹ì€ ì„±ëŠ¥ë³´ì„


---

## ğŸ”— Reference
[1] [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/pdf/2010.11929)